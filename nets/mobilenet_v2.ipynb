{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"MobileNet v2.\n",
    "MobileNet is a general architecture and can be used for multiple use cases.\n",
    "Depending on the use case, it can use different input layer size and different\n",
    "head (for example: embeddings, localization and classification).\n",
    "As described in https://arxiv.org/abs/1801.04381.\n",
    "  MobileNets: Inverted Residuals and Linear Bottlenecks: Mobile Networks for\n",
    "    Classification, Detection and Segmentation\n",
    "  Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, Liang-Chieh Chen\n",
    "\"\"\"\n",
    "\n",
    "# Tensorflow mandates these.\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from collections import namedtuple\n",
    "import functools\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "# _CONV_DEFS specifies the MobileNet body\n",
    "Conv = namedtuple('Conv', ['kernel', 'stride', 'depth'])\n",
    "InvertedResidual = namedtuple('InvertedResidual', ['kernel', 'stride', 'depth', 'num', 't']) # t is the expension factor\n",
    "_CONV_DEFS = [\n",
    "    Conv(kernel=[3, 3], stride=2, depth=32),\n",
    "    InvertedResidual(kernel=[3, 3], stride=1, depth=16, num=1, t=1),\n",
    "    InvertedResidual(kernel=[3, 3], stride=2, depth=24, num=2, t=6),\n",
    "    InvertedResidual(kernel=[3, 3], stride=2, depth=32, num=3, t=6),\n",
    "    InvertedResidual(kernel=[3, 3], stride=2, depth=64, num=4, t=6),\n",
    "    InvertedResidual(kernel=[3, 3], stride=1, depth=96, num=3, t=6),\n",
    "    InvertedResidual(kernel=[3, 3], stride=2, depth=160, num=3, t=6),\n",
    "    InvertedResidual(kernel=[3, 3], stride=1, depth=320, num=1, t=6),\n",
    "    Conv(kernel=[1, 1], stride=1, depth=1280)\n",
    "]\n",
    "\n",
    "@slim.add_arg_scope\n",
    "def _inverted_residual_bottleneck(inputs, depth, stride, expand_ratio, scope=None):\n",
    "  with tf.variable_scope(scope, 'InvertedResidual', [inputs]) as sc:\n",
    "    depth_in = slim.utils.last_dimension(inputs.get_shape(), min_rank=4)\n",
    "    output = slim.conv2d(inputs, expand_ratio*inputs.get_shape().as_list()[-1], 1, stride=1,\n",
    "                              activation_fn=tf.nn.relu6, normalizer_fn=slim.batch_norm, scope='conv')\n",
    "    output = slim.separable_conv2d(output, None, 3, depth_multiplier=1, stride=stride,\n",
    "                              activation_fn=tf.nn.relu6, normalizer_fn=slim.batch_norm, scope='depthwise')\n",
    "    output = slim.conv2d(output, depth, 1, stride=1,\n",
    "                              activation_fn=None, normalizer_fn=slim.batch_norm, scope='pointwise')\n",
    "\n",
    "    if stride==1 and depth==depth_in:\n",
    "      shortcut = inputs\n",
    "      output = shortcut + output\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "def mobilenet_v2_base(inputs,\n",
    "                      final_endpoint='Conv2d_8',\n",
    "                      min_depth=8,\n",
    "                      depth_multiplier=1.0,\n",
    "                      conv_defs=None,\n",
    "                      output_stride=None,\n",
    "                      scope=None):\n",
    "  \"\"\"Mobilenet v2.\n",
    "  Constructs a Mobilenet v2 network from inputs to the given final endpoint.\n",
    "  Args:\n",
    "    inputs: a tensor of shape [batch_size, height, width, channels].\n",
    "    final_endpoint: specifies the endpoint to construct the network up to. It\n",
    "      can be one of ['Conv2d_0', 'InvertedResidual_16_0', 'InvertedResidual_24_0', 'InvertedResidual_24_1',\n",
    "      'InvertedResidual_32_0', 'InvertedResidual_32_1', 'InvertedResidual_32_2',\n",
    "      'InvertedResidual_64_0', 'InvertedResidual_64_1', 'InvertedResidual_64_2', 'InvertedResidual_64_3',\n",
    "      'InvertedResidual_96_0', 'InvertedResidual_96_1', 'InvertedResidual_96_2',\n",
    "      'InvertedResidual_160_0', 'InvertedResidual_160_1', 'InvertedResidual_160_2', \n",
    "      'InvertedResidual_320_0', 'Conv2d_8']\n",
    "    min_depth: Minimum depth value (number of channels) for all convolution ops.\n",
    "      Enforced when depth_multiplier < 1, and not an active constraint when\n",
    "      depth_multiplier >= 1.\n",
    "    depth_multiplier: Float multiplier for the depth (number of channels)\n",
    "      for all convolution ops. The value must be greater than zero. Typical\n",
    "      usage will be to set this value in (0, 1) to reduce the number of\n",
    "      parameters or computation cost of the model.\n",
    "    conv_defs: A list of ConvDef namedtuples specifying the net architecture.\n",
    "    output_stride: An integer that specifies the requested ratio of input to\n",
    "      output spatial resolution. If not None, then we invoke atrous convolution\n",
    "      if necessary to prevent the network from reducing the spatial resolution\n",
    "      of the activation maps. Allowed values are 8 (accurate fully convolutional\n",
    "      mode), 16 (fast fully convolutional mode), 32 (classification mode).\n",
    "    scope: Optional variable_scope.\n",
    "  Returns:\n",
    "    tensor_out: output tensor corresponding to the final_endpoint.\n",
    "    end_points: a set of activations for external use, for example summaries or\n",
    "                losses.\n",
    "  Raises:\n",
    "    ValueError: if final_endpoint is not set to one of the predefined values,\n",
    "                or depth_multiplier <= 0, or the target output_stride is not\n",
    "                allowed.\n",
    "  \"\"\"\n",
    "  depth = lambda d: max(int(d * depth_multiplier), min_depth)\n",
    "  end_points = {}\n",
    "\n",
    "  # Used to find thinned depths for each layer.\n",
    "  if depth_multiplier <= 0:\n",
    "    raise ValueError('depth_multiplier is not greater than zero.')\n",
    "\n",
    "  if conv_defs is None:\n",
    "    conv_defs = _CONV_DEFS\n",
    "\n",
    "  if output_stride is not None and output_stride not in [8, 16, 32]:\n",
    "    raise ValueError('Only allowed output_stride values are 8, 16, 32.')\n",
    "\n",
    "  with tf.variable_scope(scope, 'MobilenetV2', [inputs]):\n",
    "    with slim.arg_scope([slim.conv2d, slim.separable_conv2d], padding='SAME'):\n",
    "      # The current_stride variable keeps track of the output stride of the\n",
    "      # activations, i.e., the running product of convolution strides up to the\n",
    "      # current network layer. This allows us to invoke atrous convolution\n",
    "      # whenever applying the next convolution would result in the activations\n",
    "      # having output stride larger than the target output_stride.\n",
    "      current_stride = 1\n",
    "\n",
    "      # The atrous convolution rate parameter.\n",
    "      rate = 1\n",
    "\n",
    "      net = inputs\n",
    "      for i, conv_def in enumerate(conv_defs):\n",
    "        if output_stride is not None and current_stride == output_stride:\n",
    "          # If we have reached the target output_stride, then we need to employ\n",
    "          # atrous convolution with stride=1 and multiply the atrous rate by the\n",
    "          # current unit's stride for use in subsequent layers.\n",
    "          layer_stride = 1\n",
    "          layer_rate = rate\n",
    "          rate *= conv_def.stride\n",
    "        else:\n",
    "          layer_stride = conv_def.stride\n",
    "          layer_rate = 1\n",
    "          current_stride *= conv_def.stride\n",
    "\n",
    "        if isinstance(conv_def, Conv):\n",
    "          end_point = 'Conv2d_%d' % i\n",
    "          net = slim.conv2d(net, depth(conv_def.depth), conv_def.kernel,\n",
    "                            stride=conv_def.stride,\n",
    "                            normalizer_fn=slim.batch_norm,\n",
    "                            scope=end_point)\n",
    "          end_points[end_point] = net\n",
    "          if end_point == final_endpoint:\n",
    "            return net, end_points\n",
    "\n",
    "        elif isinstance(conv_def, InvertedResidual):\n",
    "          for n in range(conv_def.num):\n",
    "            end_point = 'InvertedResidual_{}_{}'.format(conv_def.depth, n)\n",
    "            stride = conv_def.stride if n == 0 else 1\n",
    "            net = _inverted_residual_bottleneck(net, depth(conv_def.depth), stride, conv_def.t, scope=end_point)\n",
    "            end_points[end_point] = net\n",
    "            if end_point == final_endpoint:\n",
    "              return net, end_points\n",
    "        else:\n",
    "          raise ValueError('Unknown convolution type %s for layer %d'\n",
    "                           % (conv_def.ltype, i))\n",
    "  raise ValueError('Unknown final endpoint %s' % final_endpoint)\n",
    "\n",
    "\n",
    "def mobilenet_v2(inputs,\n",
    "                 num_classes=1000,\n",
    "                 dropout_keep_prob=0.999,\n",
    "                 is_training=True,\n",
    "                 min_depth=8,\n",
    "                 depth_multiplier=1.0,\n",
    "                 conv_defs=None,\n",
    "                 prediction_fn=tf.contrib.layers.softmax,\n",
    "                 spatial_squeeze=True,\n",
    "                 reuse=None,\n",
    "                 scope='MobilenetV2',\n",
    "                 global_pool=False):\n",
    "  \"\"\"Mobilenet v2 model for classification.\n",
    "  Args:\n",
    "    inputs: a tensor of shape [batch_size, height, width, channels].\n",
    "    num_classes: number of predicted classes. If 0 or None, the logits layer\n",
    "      is omitted and the input features to the logits layer (before dropout)\n",
    "      are returned instead.\n",
    "    dropout_keep_prob: the percentage of activation values that are retained.\n",
    "    is_training: whether is training or not.\n",
    "    min_depth: Minimum depth value (number of channels) for all convolution ops.\n",
    "      Enforced when depth_multiplier < 1, and not an active constraint when\n",
    "      depth_multiplier >= 1.\n",
    "    depth_multiplier: Float multiplier for the depth (number of channels)\n",
    "      for all convolution ops. The value must be greater than zero. Typical\n",
    "      usage will be to set this value in (0, 1) to reduce the number of\n",
    "      parameters or computation cost of the model.\n",
    "    conv_defs: A list of ConvDef namedtuples specifying the net architecture.\n",
    "    prediction_fn: a function to get predictions out of logits.\n",
    "    spatial_squeeze: if True, logits is of shape is [B, C], if false logits is\n",
    "        of shape [B, 1, 1, C], where B is batch_size and C is number of classes.\n",
    "    reuse: whether or not the network and its variables should be reused. To be\n",
    "      able to reuse 'scope' must be given.\n",
    "    scope: Optional variable_scope.\n",
    "    global_pool: Optional boolean flag to control the avgpooling before the\n",
    "      logits layer. If false or unset, pooling is done with a fixed window\n",
    "      that reduces default-sized inputs to 1x1, while larger inputs lead to\n",
    "      larger outputs. If true, any input size is pooled down to 1x1.\n",
    "  Returns:\n",
    "    net: a 2D Tensor with the logits (pre-softmax activations) if num_classes\n",
    "      is a non-zero integer, or the non-dropped-out input to the logits layer\n",
    "      if num_classes is 0 or None.\n",
    "    end_points: a dictionary from components of the network to the corresponding\n",
    "      activation.\n",
    "  Raises:\n",
    "    ValueError: Input rank is invalid.\n",
    "  \"\"\"\n",
    "  input_shape = inputs.get_shape().as_list()\n",
    "  if len(input_shape) != 4:\n",
    "    raise ValueError('Invalid input tensor rank, expected 4, was: %d' %\n",
    "                     len(input_shape))\n",
    "\n",
    "  with tf.variable_scope(scope, 'MobilenetV2', [inputs], reuse=reuse) as scope:\n",
    "    with slim.arg_scope([slim.batch_norm, slim.dropout],\n",
    "                        is_training=is_training):\n",
    "      net, end_points = mobilenet_v2_base(inputs, scope=scope,\n",
    "                                          min_depth=min_depth,\n",
    "                                          depth_multiplier=depth_multiplier,\n",
    "                                          conv_defs=conv_defs)\n",
    "      with tf.variable_scope('Logits'):\n",
    "        if global_pool:\n",
    "          # Global average pooling.\n",
    "          net = tf.reduce_mean(net, [1, 2], keep_dims=True, name='global_pool')\n",
    "          end_points['global_pool'] = net\n",
    "        else:\n",
    "          # Pooling with a fixed kernel size.\n",
    "          kernel_size = _reduced_kernel_size_for_small_input(net, [7, 7])\n",
    "          net = slim.avg_pool2d(net, kernel_size, padding='VALID',\n",
    "                                scope='AvgPool_1a')\n",
    "          end_points['AvgPool_1a'] = net\n",
    "        if not num_classes:\n",
    "          return net, end_points\n",
    "        # 1 x 1 x 1024\n",
    "        net = slim.dropout(net, keep_prob=dropout_keep_prob, scope='Dropout_1b')\n",
    "        logits = slim.conv2d(net, num_classes, [1, 1], activation_fn=None,\n",
    "                             normalizer_fn=None, scope='Conv2d_1c_1x1')\n",
    "        if spatial_squeeze:\n",
    "          logits = tf.squeeze(logits, [1, 2], name='SpatialSqueeze')\n",
    "      end_points['Logits'] = logits\n",
    "      if prediction_fn:\n",
    "        end_points['Predictions'] = prediction_fn(logits, scope='Predictions')\n",
    "  return logits, end_points\n",
    "\n",
    "mobilenet_v2.default_image_size = 224\n",
    "\n",
    "\n",
    "def wrapped_partial(func, *args, **kwargs):\n",
    "  partial_func = functools.partial(func, *args, **kwargs)\n",
    "  functools.update_wrapper(partial_func, func)\n",
    "  return partial_func\n",
    "\n",
    "\n",
    "mobilenet_v2_075 = wrapped_partial(mobilenet_v2, depth_multiplier=0.75)\n",
    "mobilenet_v2_050 = wrapped_partial(mobilenet_v2, depth_multiplier=0.50)\n",
    "mobilenet_v2_025 = wrapped_partial(mobilenet_v2, depth_multiplier=0.25)\n",
    "\n",
    "\n",
    "def _reduced_kernel_size_for_small_input(input_tensor, kernel_size):\n",
    "  \"\"\"Define kernel size which is automatically reduced for small input.\n",
    "  If the shape of the input images is unknown at graph construction time this\n",
    "  function assumes that the input images are large enough.\n",
    "  Args:\n",
    "    input_tensor: input tensor of size [batch_size, height, width, channels].\n",
    "    kernel_size: desired kernel size of length 2: [kernel_height, kernel_width]\n",
    "  Returns:\n",
    "    a tensor with the kernel size.\n",
    "  \"\"\"\n",
    "  shape = input_tensor.get_shape().as_list()\n",
    "  if shape[1] is None or shape[2] is None:\n",
    "    kernel_size_out = kernel_size\n",
    "  else:\n",
    "    kernel_size_out = [min(shape[1], kernel_size[0]),\n",
    "                       min(shape[2], kernel_size[1])]\n",
    "  return kernel_size_out\n",
    "\n",
    "\n",
    "def mobilenet_v2_arg_scope(is_training=True,\n",
    "                           weight_decay=0.00004,\n",
    "                           stddev=0.09,\n",
    "                           regularize_depthwise=False):\n",
    "  \"\"\"Defines the default MobilenetV2 arg scope.\n",
    "  Args:\n",
    "    is_training: Whether or not we're training the model.\n",
    "    weight_decay: The weight decay to use for regularizing the model.\n",
    "    stddev: The standard deviation of the trunctated normal weight initializer.\n",
    "    regularize_depthwise: Whether or not apply regularization on depthwise.\n",
    "  Returns:\n",
    "    An `arg_scope` to use for the mobilenet v2 model.\n",
    "  \"\"\"\n",
    "  batch_norm_params = {\n",
    "      'is_training': is_training,\n",
    "      'center': True,\n",
    "      'scale': True,\n",
    "      'decay': 0.9997,\n",
    "      'epsilon': 0.001,\n",
    "  }\n",
    "\n",
    "  # Set weight_decay for weights in Conv and DepthSepConv layers.\n",
    "  weights_init = tf.truncated_normal_initializer(stddev=stddev)\n",
    "  regularizer = tf.contrib.layers.l2_regularizer(weight_decay)\n",
    "  if regularize_depthwise:\n",
    "    depthwise_regularizer = regularizer\n",
    "  else:\n",
    "    depthwise_regularizer = None\n",
    "  with slim.arg_scope([slim.conv2d, slim.separable_conv2d],\n",
    "                      weights_initializer=weights_init,\n",
    "                      activation_fn=tf.nn.relu6, normalizer_fn=slim.batch_norm):\n",
    "    with slim.arg_scope([slim.batch_norm], **batch_norm_params):\n",
    "      with slim.arg_scope([slim.conv2d], weights_regularizer=regularizer):\n",
    "        with slim.arg_scope([slim.separable_conv2d],\n",
    "                            weights_regularizer=depthwise_regularizer) as sc:\n",
    "          return sc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
